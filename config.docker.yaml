# PLLM Docker Configuration

server:
  port: 8080
  admin_port: 9090
  metrics_port: 8081

cors:
  allowed_origins: ["http://localhost:3000", "http://localhost:5173", "*"]
  allowed_methods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
  allowed_headers: ["Content-Type", "Authorization", "X-API-Key"]
  exposed_headers: ["X-Request-ID"]
  allow_credentials: true
  max_age: 3600

database:
  url: postgres://pllm:pllm@postgres:5432/pllm?sslmode=disable

redis:
  url: redis://redis:6379

jwt:
  secret_key: your-super-secret-jwt-key-change-this

admin:
  username: admin
  password: changeme123!
  email: admin@pllm.io

logging:
  level: debug

# Authentication configuration
auth:
  master_key: sk-master-dev-key-change-in-production
  require_auth: true
  dex:
    enabled: true
    issuer: "http://localhost:5556/dex"
    client_id: "pllm-web"
    client_secret: "pllm-web-secret"
    redirect_url: "http://localhost:3000/auth/callback"
    scopes: ["openid", "profile", "email", "groups"]

# Router configuration with adaptive routing for high-load scenarios
router:
  routing_strategy: "latency-based"
  circuit_breaker_enabled: true
  circuit_breaker_threshold: 5
  circuit_breaker_cooldown: 30s

  # Fallback chains - automatic failover when primary models are slow or failing
  fallbacks:
    my-gpt-4: ["my-gpt-35-turbo"]
    my-gpt-35-turbo: ["my-gpt-35-turbo-16k"]

# Model list - Users call these model names in API requests
model_list:
  # Primary GPT-4 instance
  - model_name: my-gpt-4
    params:
      model: gpt-4
      api_key: ${OPENAI_API_KEY}
    rpm: 60
    tpm: 90000

  # Primary GPT-3.5-Turbo instance
  - model_name: my-gpt-35-turbo
    params:
      model: gpt-3.5-turbo
      api_key: ${OPENAI_API_KEY}
    rpm: 200
    tpm: 90000

  # GPT-3.5-Turbo-16K as fallback
  - model_name: my-gpt-35-turbo-16k
    params:
      model: gpt-3.5-turbo-16k
      api_key: ${OPENAI_API_KEY}
    rpm: 200
    tpm: 180000

  # OpenRouter models - uses full model path as OpenRouter expects
  - model_name: deepseek-v3-free
    params:
      model: deepseek/deepseek-chat-v3-0324:free # OpenRouter format: provider/model
      api_key: ${OPENROUTER_API_KEY}
      api_base: https://openrouter.ai/api/v1
    rpm: 60
    tpm: 50000

  - model_name: gemini-2.0-flash-exp-free
    params:
      model: google/gemini-2.0-flash-exp:free # OpenRouter format: provider/model
      api_key: ${OPENROUTER_API_KEY}
      api_base: https://openrouter.ai/api/v1
    rpm: 60
    tpm: 50000

  - model_name: gpt-oss-20b-free
    params:
      model: openai/gpt-oss-20b:free # OpenRouter format: provider/model
      api_key: ${OPENROUTER_API_KEY}
      api_base: https://openrouter.ai/api/v1
    rpm: 60
    tpm: 50000
